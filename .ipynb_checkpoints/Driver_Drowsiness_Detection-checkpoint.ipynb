{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af0f255",
   "metadata": {},
   "source": [
    "# Driver Drowsiness Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd6ebbb",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07e832ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from keras.models import model_from_json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eee60e",
   "metadata": {},
   "source": [
    "## Loading CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "363ffef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d647bcdf",
   "metadata": {},
   "source": [
    "### Face and Eye Detection using Haar Cascade Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "387ee2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Closed\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Open\n",
      "Closed\n",
      "Open\n",
      "Closed\n",
      "Open\n"
     ]
    }
   ],
   "source": [
    "face_cascade_name = \"haarcascade_frontalface_default.xml\"\n",
    "eyes_cascade_name = \"haarcascade_eye_tree_eyeglasses.xml\"\n",
    "l_eye_cascade_name = \"haarcascade_lefteye_2splits.xml\"\n",
    "r_eye_cascade_name = \"haarcascade_righteye_2splits.xml\"\n",
    "\n",
    "face_cascade = cv.CascadeClassifier(face_cascade_name)\n",
    "eye_cascade = cv.CascadeClassifier(eyes_cascade_name)\n",
    "l_eye_cascade = cv.CascadeClassifier(l_eye_cascade_name)\n",
    "r_eye_cascade = cv.CascadeClassifier(r_eye_cascade_name)\n",
    "#Works with gray scale images. So converting into GrayScale images\n",
    "\n",
    "font = cv.FONT_HERSHEY_COMPLEX_SMALL\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    _,  frame = cap.read()\n",
    "    \n",
    "    gray = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "#         eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        l_eye = l_eye_cascade.detectMultiScale(roi_gray)\n",
    "        r_eye = r_eye_cascade.detectMultiScale(roi_gray)\n",
    "        cv.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 3)\n",
    "        \n",
    "        for (ex,ey,ew,eh) in l_eye:\n",
    "            #Prediction\n",
    "            l_eye_frame = frame[ey:ey+eh,ex:ex+ew]\n",
    "            l_eye_frame = cv.resize(l_eye_frame,(64,64))\n",
    "            l_eye_frame = l_eye_frame.reshape(64,64,-1)\n",
    "            l_eye_frame = image.img_to_array(l_eye_frame)\n",
    "            l_eye_frame = np.expand_dims(l_eye_frame, axis = 0)\n",
    "            result = model.predict(l_eye_frame)\n",
    "                      \n",
    "            cv.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0,255,0), 2)\n",
    "            \n",
    "            if result[0][0] == 0:\n",
    "                cv.putText(frame,\"Closed\",(10,h-20), font, 1,(255,255,255),1,cv.LINE_AA)\n",
    "                print(\"Closed\")\n",
    "            else:\n",
    "                cv.putText(frame,\"Open\",(10,h-20), font, 1,(255,255,255),1,cv.LINE_AA)\n",
    "                print(\"Open\")\n",
    "            \n",
    "        for (ex,ey,ew,eh) in r_eye:\n",
    "            #Prediction\n",
    "            r_eye_frame = frame[ey:ey+eh,ex:ex+ew]\n",
    "            r_eye_frame = cv.resize(r_eye_frame,(64,64))\n",
    "            r_eye_frame = r_eye_frame.reshape(64,64,-1)\n",
    "            r_eye_frame = image.img_to_array(r_eye_frame)\n",
    "            r_eye_frame = np.expand_dims(r_eye_frame, axis = 0)\n",
    "            result = model.predict(r_eye_frame)\n",
    "            \n",
    "            cv.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0,255,0), 2)\n",
    "            \n",
    "            if result[0][0] == 0:\n",
    "                cv.putText(frame,\"Closed\",(w-20,h-20), font, 1,(255,255,255),1,cv.LINE_AA)\n",
    "            else:\n",
    "                cv.putText(frame,\"Open\",(w-20,h-20), font, 1,(255,255,255),1,cv.LINE_AA)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    cv.imshow('img',frame)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv.destroyAllWindows()\n",
    "        cap.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0410bdf",
   "metadata": {},
   "source": [
    "### Driver Drowsiness Detection using Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15a10412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "# from pygame import mixer\n",
    "import time\n",
    "\n",
    "\n",
    "# mixer.init()\n",
    "# sound = mixer.Sound('alarm.wav')\n",
    "\n",
    "face = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_alt.xml')\n",
    "leye = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_lefteye_2splits.xml')\n",
    "reye = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_righteye_2splits.xml')\n",
    "\n",
    "\n",
    "\n",
    "lbl=['Close','Open']\n",
    "\n",
    "model = load_model('models/cnncat2.h5')\n",
    "path = os.getcwd()\n",
    "cap = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "count=0\n",
    "score=0\n",
    "thicc=2\n",
    "rpred=[99]\n",
    "lpred=[99]\n",
    "\n",
    "while(True):\n",
    "    _, frame = cap.read()\n",
    "    height,width = frame.shape[:2] \n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face.detectMultiScale(gray,minNeighbors=5,scaleFactor=1.1,minSize=(25,25))\n",
    "    left_eye = leye.detectMultiScale(gray)\n",
    "    right_eye =  reye.detectMultiScale(gray)\n",
    "\n",
    "    cv2.rectangle(frame, (0,height-50) , (200,height) , (0,0,0) , thickness=cv2.FILLED )\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y) , (x+w,y+h) , (100,100,100) , 1 )\n",
    "\n",
    "    for (x,y,w,h) in right_eye:\n",
    "        r_eye=frame[y:y+h,x:x+w]\n",
    "        count=count+1\n",
    "        r_eye = cv2.cvtColor(r_eye,cv2.COLOR_BGR2GRAY)\n",
    "        r_eye = cv2.resize(r_eye,(24,24))\n",
    "        r_eye= r_eye/255\n",
    "        r_eye=  r_eye.reshape(24,24,-1)\n",
    "        r_eye = np.expand_dims(r_eye,axis=0)\n",
    "        rpred = model.predict(r_eye)\n",
    "        if(rpred[0][0]==1):\n",
    "            lbl='Open' \n",
    "        if(rpred[0][0]==0):\n",
    "            lbl='Closed'\n",
    "        break\n",
    "\n",
    "    for (x,y,w,h) in left_eye:\n",
    "        l_eye=frame[y:y+h,x:x+w]\n",
    "        count=count+1\n",
    "        l_eye = cv2.cvtColor(l_eye,cv2.COLOR_BGR2GRAY)  \n",
    "        l_eye = cv2.resize(l_eye,(24,24))\n",
    "        l_eye= l_eye/255\n",
    "        l_eye=l_eye.reshape(24,24,-1)\n",
    "        l_eye = np.expand_dims(l_eye,axis=0)\n",
    "        lpred = model.predict(l_eye)\n",
    "        if(lpred[0][0]==1):\n",
    "            lbl='Open'   \n",
    "        if(lpred[0][0]==0):\n",
    "            lbl='Closed'\n",
    "        break\n",
    "\n",
    "    if(rpred[0][0]==0 and lpred[0][0]==0):\n",
    "        score=score+1\n",
    "        cv2.putText(frame,\"Closed\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    # if(rpred[0]==1 or lpred[0]==1):\n",
    "    else:\n",
    "        score=score-1\n",
    "        cv2.putText(frame,\"Open\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    \n",
    "        \n",
    "    if(score<0):\n",
    "        score=0   \n",
    "    cv2.putText(frame,'Score:'+str(score),(100,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    if(score>15):\n",
    "        #person is feeling sleepy so we beep the alarm\n",
    "        cv2.imwrite(os.path.join(path,'image.jpg'),frame)\n",
    "#         try:\n",
    "#             sound.play()\n",
    "            \n",
    "#         except:  # isplaying = False\n",
    "#             pass\n",
    "        if(thicc<16):\n",
    "            thicc= thicc+2\n",
    "        else:\n",
    "            thicc=thicc-2\n",
    "            if(thicc<2):\n",
    "                thicc=2\n",
    "        cv2.rectangle(frame,(0,0),(width,height),(0,0,255),thicc) \n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
